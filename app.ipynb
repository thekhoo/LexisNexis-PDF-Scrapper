{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2960686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2ed9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request user to input the filename without the .pdf\n",
    "# filename = input('What is the file name?\\n')\n",
    "filename = 'F17'\n",
    "\n",
    "# Enter the sections to be extracted here\n",
    "section_to_extract = [18,6,7,8,9,12,13,14,15,16,17,20,21,22,23,24,25,27]\n",
    "section_to_extract.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097bba14",
   "metadata": {},
   "source": [
    "## Getting the PDF File Text\n",
    "\n",
    "This section of code will handle obtaining the file and the text within that pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0552495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the File\n",
    "file = open(f'data/{filename}.pdf','rb')\n",
    "\n",
    "# Create PyPDF2 Reader Object\n",
    "reader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "# Get the Text from the file\n",
    "text = ''\n",
    "text_arr = []\n",
    "\n",
    "for i in range(reader.numPages):\n",
    "    # Get the current page\n",
    "    page = reader.getPage(i)\n",
    "    # Extract the text\n",
    "    current_text = page.extract_text()\n",
    "    # Append to master text variable\n",
    "    text += current_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57926804",
   "metadata": {},
   "source": [
    "## Separate the text by End of Document\n",
    "\n",
    "This section of code will separate the text by the phrase \"End of Document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3efcfd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "section_regex=r\"\\.\\d{1,3}\\n\"\n",
    "print(type(section_regex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d427d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['F17.5', 'F17.6', 'F17.7', 'F17.17', 'F17.8', 'F17.9', 'F17.84', 'F17.10', 'F17.11', 'F17.12', 'F17.13', 'F17.14', 'F17.15', 'F17.39', 'F17.16', 'F17.21', 'F17.18', 'F17.19', 'F17.20', 'F17.22', 'F17.23', 'F17.24', 'F17.25', 'F17.26', 'F17.27', 'F17.28', 'F17.29', 'F17.30', 'F17.38', 'F17.31', 'F17.32', 'F17.33', 'F17.34', 'F17.35', 'F17.36', 'F17.37', 'F17.40', 'F17.41', 'F17.42', 'F17.43', 'F17.44', 'F17.45', 'F17.46', 'F17.47', 'F17.48', 'F17.49', 'F17.50', 'F17.51', 'F17.52', 'F17.53', 'F17.54', 'F17.55', 'F17.56', 'F17.57', 'F17.58', 'F17.59', 'F17.60', 'F17.61', 'F17.62', 'F17.63', 'F17.64', 'F17.65', 'F17.66', 'F17.67', 'F17.68', 'F17.69', 'F17.70', 'F17.71', 'F17.72', 'F17.73', 'F17.74', 'F17.75', 'F17.76', 'F17.77', 'F17.78', 'F17.79', 'F17.80', 'F17.81', 'F17.82', 'F17.83', 'F17.85', 'F17.86', 'F17.87', 'F17.88', 'F17.89', 'F17.90', 'F17.91', 'F17.92', 'F17.93', 'F17.94', 'F17.95', 'F17.96', 'F17.97', 'F17.98', 'F17.99'])\n"
     ]
    }
   ],
   "source": [
    "# EOD Regex\n",
    "eod_regex = r\"End\\sof\\sDocument\"\n",
    "eod_text = re.split(eod_regex,text)\n",
    "\n",
    "# Always drop the first section - Anything before the first End of Document not important\n",
    "eod_text.pop(0)\n",
    "\n",
    "# Main and Sub Headings for the pages within the document\n",
    "main_heading = ''\n",
    "sub_heading = ''\n",
    "\n",
    "main_dict = {}\n",
    "\n",
    "for item in eod_text:\n",
    "\n",
    "    # Title Regex\n",
    "    title_regex = r\"Blackstone's\\sCriminal\\sPractice\\s2022\"\n",
    "    item_arr = re.split(title_regex,item)\n",
    "    \n",
    "    # Only work on arrays that have a length more than 1\n",
    "    # At the very end of the document, there will be \"End of Document\" and the next thing will only be a \\n\n",
    "    \n",
    "    if len(item_arr) > 1:\n",
    "        page_heading = item_arr[0].replace('\\n','')\n",
    "        page_text = item_arr[1]\n",
    "        \n",
    "        if page_heading.isupper():\n",
    "            # This is a main heading\n",
    "            # Update main_heading\n",
    "            main_heading = page_heading\n",
    "        else:\n",
    "            # This is a sub heading\n",
    "            # Update sub_heading\n",
    "            sub_heading = page_heading\n",
    "        \n",
    "        # Check if rest of text on the page contains sections\n",
    "        # Section Regex\n",
    "        section_regex = r'\\n' + re.escape(filename) + r'\\.\\d{1,3}'\n",
    "\n",
    "        # Create a Regex to Identify section numbers\n",
    "        sections = re.findall(section_regex,page_text)\n",
    "        sections = [s.replace('\\n','') for s in sections]\n",
    "\n",
    "        # Split the text into an array\n",
    "        section_text = re.split(section_regex,page_text)\n",
    "        \n",
    "        # Check if there are any sections on the page\n",
    "        if len(sections) > 0:\n",
    "            # There are sections. Proceed to split\n",
    "            # Pop the first item of the array (The text in between the page title and first section)\n",
    "            section_text.pop(0)\n",
    "            \n",
    "            for section, text_item in zip(sections, section_text):\n",
    "                text_item = text_item.replace(f'{sub_heading}\\n','')\n",
    "                current_dict = {\n",
    "                    section: {\n",
    "                        \"section_heading\": main_heading,\n",
    "                        \"section_subheading\": sub_heading,\n",
    "                        \"section_text\": text_item\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                main_dict.update(current_dict)\n",
    "                \n",
    "print(main_dict.keys())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52afc123",
   "metadata": {},
   "source": [
    "## Separate the text by Section\n",
    "\n",
    "This section of code will separate the text by section and return a dictionary of section and the corresponding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb7b2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criminal trials in England and Wales are either trials on indictment in the Crown Court or summary trials in a \n",
      "magistrates' court. This section deals with (a) the classification of offences according to whether they: (i) must be \n",
      "tried on indictment, or (ii) may be tried either on indictment or summarily, or (iii) must be tried summarily; and (b) the \n",
      "procedure for determining the appropriate mode of trial in those cases where there is a choice.\n",
      "End of Document\n",
      "CLASSIFICATION OF OFFENCES\n",
      "Blackstone's Criminal Practice 2022  >  PART D PROCEDURE  >  Section D6 Classification of \n",
      "Offences and Determining Allocation (Mode of Trial)\n",
      "End of Document\n",
      "Definition of the Classes of Offences\n",
      "Blackstone's Criminal Practice 2022  >  PART D PROCEDURE  >  Section D6 Classification of \n",
      "Offences and Determining Allocation (Mode of Trial)  >  CLASSIFICATION OF OFFENCES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Section Regex\n",
    "section_regex = re.escape(filename) + r'\\.\\d{1,2}\\n'\n",
    "\n",
    "# Create a Regex to Identify section numbers\n",
    "sections_full = re.findall(section_regex,text)\n",
    "\n",
    "# Split the text into an array\n",
    "section_text = re.split(section_regex,text)\n",
    "\n",
    "# Get a list of Sections\n",
    "sections = [s.strip('\\n') for s in sections_full]\n",
    "\n",
    "# Remove the first section (Before D#.1)\n",
    "section_text.pop(0)\n",
    "\n",
    "# Create Dictionary\n",
    "doc_dict = dict(zip(sections,section_text))\n",
    "print(doc_dict[\"D6.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436cd290",
   "metadata": {},
   "source": [
    "## Extract Target Data\n",
    "\n",
    "This section of code will search for the sections specified by the user and return it as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0b1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_linespace_OLD(text):\n",
    "    # Split by .\\n to get an array\n",
    "    # linespace_regex = r'(?<=[a-z)])\\.\\n(?=[A-Z(])'\n",
    "    linespace_regex = r'[\\.;:]\\n'\n",
    "    \n",
    "    delimiter_arr = re.findall(linespace_regex,text)\n",
    "    text_arr = re.split(linespace_regex,text)\n",
    "    \n",
    "    # Strip '\\n'\n",
    "    text_arr_formatted = [s.replace('\\n','') for s in text_arr]\n",
    "    \n",
    "    # Replace '\\n' with '\\r\\n'\n",
    "    delimiter_arr_formatted = [s.replace('\\n','') for s in delimiter_arr]\n",
    "    \n",
    "    # Join together\n",
    "    full_text_arr = []\n",
    "    \n",
    "    for idx, text_formatted in enumerate(text_arr_formatted):\n",
    "        if idx == len(text_arr_formatted) - 1:\n",
    "            \n",
    "            # Check if the section starts with \"End of Document\"\n",
    "            if text_formatted.find(\"End of Document\") == -1:\n",
    "                # End of Document not Found\n",
    "                full_text = text_formatted\n",
    "                \n",
    "        elif idx > 0:\n",
    "            # Start implementing delimiter + text\n",
    "            full_text = delimiter_arr_formatted[idx-1]\n",
    "            full_text += text_formatted\n",
    "        \n",
    "        else:\n",
    "            # First section of the text won't have a delimiter\n",
    "            full_text += text_formatted\n",
    "        \n",
    "        full_text_arr.append(full_text)\n",
    "\n",
    "        \n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae55cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_linespace(text_raw) -> list:\n",
    "    \n",
    "    linespace_regex = r'[\\.;:]\\n'\n",
    "    \n",
    "    delimiter_arr = re.findall(linespace_regex,text_raw)\n",
    "    text_arr = re.split(linespace_regex,text_raw)\n",
    "    \n",
    "    # Strip '\\n'\n",
    "    text_arr_formatted = [s.replace('\\n','') for s in text_arr]\n",
    "    \n",
    "    # Replace '\\n' with '\\r\\n'\n",
    "    delimiter_arr_formatted = [s.replace('\\n','') for s in delimiter_arr]\n",
    "    \n",
    "    text_delim_zip = zip(text_arr_formatted,delimiter_arr_formatted)\n",
    "    \n",
    "    text_arr = []\n",
    "    \n",
    "    for text, delimiter in text_delim_zip:\n",
    "        text_arr.append(text + delimiter)\n",
    "    \n",
    "    return text_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367c427",
   "metadata": {},
   "source": [
    "## Generating Word File\n",
    "\n",
    "This section will start creating the word file based on the text obtained and sections highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b0428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT, WD_BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335d75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c90ca71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<docx.text.paragraph.Paragraph at 0x7faa817b18e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Heading for Document\n",
    "doc.add_heading(f\"{filename} Compilation\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1169c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Sections and Text to Document\n",
    "for target in section_to_extract:\n",
    "    section_heading = f'{filename}.{target}'\n",
    "    section_text = remove_linespace(doc_dict[section_heading])\n",
    "    \n",
    "    # Add Heading\n",
    "    doc.add_heading(section_heading)\n",
    "    \n",
    "    # Add text\n",
    "    for text_item in section_text:\n",
    "        paragraph = doc.add_paragraph(text_item)\n",
    "        paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
    "        paragraph.paragraph_format.space_after = Pt(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f5c5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Document\n",
    "doc.save(f'output/{filename}.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b03ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4a792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
